{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **(Binary) Classification**"
      ],
      "metadata": {
        "id": "1ZYOirmzkc2N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS4f56FMXWIW"
      },
      "source": [
        "# **Global Constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22GlbXx0XWIW"
      },
      "source": [
        "JAVA_HOME = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "GDRIVE_DIR = \"/content/drive\"\n",
        "GDRIVE_HOME_DIR = GDRIVE_DIR + \"/MyDrive\"\n",
        "GDRIVE_DATA_DIR = GDRIVE_HOME_DIR + \"/Teaching/2022-23/2022-23-BDC/datasets\"\n",
        "DATASET_URL = \"https://github.com/gtolomei/big-data-computing/raw/master/datasets/bank-marketing.csv.bz2\"\n",
        "GDRIVE_DATASET_FILE = GDRIVE_DATA_DIR + \"/\" + DATASET_URL.split(\"/\")[-1]\n",
        "\n",
        "RANDOM_SEED = 42 # for reproducibility"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtmWjQUVSvq2"
      },
      "source": [
        "# **Spark + Google Colab Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlRW_JLjSvrA"
      },
      "source": [
        "## **1.** Install PySpark and related dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si82CaUYSvrA"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark\n",
        "# Alternatively, if you want to install a specific version of pyspark:\n",
        "#!pip install pyspark==3.2.1\n",
        "!pip install -U -q PyDrive # To use files that are stored in Google Drive directly (e.g., without downloading them from an external URL)\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = JAVA_HOME\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOOZptveSvrB"
      },
      "source": [
        "## **2.** Import useful Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX7xDYw4SvrB"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYvwgAvGSvrB"
      },
      "source": [
        "## **3.** Create Spark context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fhi5bmOeSvrB"
      },
      "outputs": [],
      "source": [
        "# Create the session\n",
        "conf = SparkConf().\\\n",
        "                set('spark.ui.port', \"4050\").\\\n",
        "                set('spark.executor.memory', '4G').\\\n",
        "                set('spark.driver.memory', '45G').\\\n",
        "                set('spark.driver.maxResultSize', '10G').\\\n",
        "                setAppName(\"PySparkTutorial\").\\\n",
        "                setMaster(\"local[*]\")\n",
        "\n",
        "# Create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWSfSKX6SvrB"
      },
      "source": [
        "## **4.** Create <code>ngrok</code> tunnel to check the Spark UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9luPyVNSvrB"
      },
      "outputs": [],
      "source": [
        "# Install ngrok\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKGaSV0F7Sh5"
      },
      "outputs": [],
      "source": [
        "# Be sure you create your own account at https://dashboard.ngrok.com/login and replace the token string below with yours\n",
        "!ngrok authtoken 2MamtHU170jRTFqA7ai0WZFniY9_825Vvne665fhVDZdRKNHT # Replace with your own authtoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROQzVuNu7ZE_"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Open a ngrok tunnel on the port 4050 where Spark is running\n",
        "port = '4050'\n",
        "public_url = ngrok.connect(port).public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwwPauep7bm4"
      },
      "outputs": [],
      "source": [
        "print(\"To access the Spark Web UI console, please click on the following link to the ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo9prfkJSvrB"
      },
      "source": [
        "## **5.** Link Colab to our Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au2-MqC-SvrB"
      },
      "outputs": [],
      "source": [
        "# Point Colaboratory to our Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(GDRIVE_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEsgE-WfSvrB"
      },
      "source": [
        "## **6.** Check everything is ok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X312aarSvrB"
      },
      "outputs": [],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEvgsXRkSvrC"
      },
      "outputs": [],
      "source": [
        "sc._conf.getAll()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu77QbD2vC_o"
      },
      "source": [
        "# **The Prediction Task**\n",
        "\n",
        "In this notebook, we will be using a dataset from [Kaggle](https://www.kaggle.com/rouseguy/bankbalanced/data) containing a _balanced_ random sample of **11,162 instances** extracted from the original (_unbalanced_) dataset of 45,211 examples, available from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing).\n",
        "\n",
        "The dataset is related with direct marketing campaigns (i.e., phone calls) of a Portuguese banking institution. Each record $(\\mathbf{x}_i, y_i)$ contains customer information represented by means of **16 features** (i.e., $\\mathbf{x}_i = x_{i,1}, \\ldots, x_{i,16}$), along with a **binary response** ($y_i$), which indicates whether the given customer subscribes ($y_i = 1$) or not ($y_i = 0$) the term deposit proposed by the phone marketing campaign.\n",
        "\n",
        "The classification goal is, given a _new_ customer, to predict if she/he will subscribe a term deposit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-vLczwIuUhG"
      },
      "source": [
        "# **1. Data Collection**\n",
        "\n",
        "This is the first step we need to accomplish before going any further. The dataset will be downloaded directly to our Google Drive, as usual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5fI3wiGvKBl"
      },
      "source": [
        "### **Download dataset file from URL directly to our Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxrLDE_4e7KH"
      },
      "source": [
        "def get_data(dataset_url, dest, chunk_size=1024):\n",
        "  response = requests.get(dataset_url, stream=True)\n",
        "  if response.status_code == 200:\n",
        "    with open(dest, \"wb\") as file:\n",
        "      for block in response.iter_content(chunk_size=chunk_size): \n",
        "        if block: \n",
        "          file.write(block)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quiuGbfyv8vT"
      },
      "source": [
        "print(\"Retrieving dataset from URL: {} ...\".format(DATASET_URL))\n",
        "get_data(DATASET_URL, GDRIVE_DATASET_FILE)\n",
        "print(\"Dataset successfully retrieved and stored at: {}\".format(GDRIVE_DATASET_FILE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DevlrMcPw1ZI"
      },
      "source": [
        "### **Read dataset file into a Spark Dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKi5Hd60FFcX"
      },
      "source": [
        "bank_df = spark.read.load(GDRIVE_DATASET_FILE, \n",
        "                         format=\"csv\", \n",
        "                         sep=\",\", \n",
        "                         inferSchema=\"true\", \n",
        "                         header=\"true\"\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPTd8ep9x74H"
      },
      "source": [
        "### **Check the shape of the loaded dataset, i.e., number of rows and columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyRyYqeXGA4l"
      },
      "source": [
        "print(\"The shape of the dataset is {:d} rows by {:d} columns\".format(bank_df.count(), len(bank_df.columns)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WC4RPQgyEsB"
      },
      "source": [
        "### **Print out the schema of the loaded dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3KhtSnvGIwG"
      },
      "source": [
        "bank_df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXlcRfzmNNCv"
      },
      "source": [
        "### **Dataset Shape and Schema**\n",
        "\n",
        "The dataset contains **11,162** records of marketing campaigns; each record, is represented by the following set of **17** columns:\n",
        "- `age`: The customer's age (_numerical_, _discrete_);\n",
        "- `job`: The customer's type of job (_categorical_, _nominal_: \"`admin.`\", \"`blue-collar`\", \"`entrepreneur`\", \"`housemaid`\", \"`management`\", \"`retired`\", \"`self-employed`\", \"`services`\", \"`student`\" \"`technician`\", \"`unemployed`\", \"`unknown`\");\n",
        "- `marital`: The customer's marital status (_categorical_, _nominal_: \"`divorced`\", \"`married`\", \"`single`\", \"`unknown`\") [**NOTE:** \"`divorced`\" means divorced or widowed];\n",
        "- `education`: The customer's level of education (_categorical_, _ordinal_: \"`basic.4y`\", \"`basic.6y`\", \"`basic.9y`\", \"`high.school`\", \"`illiterate`\", \"`professional.course`\", \"`university.degree`\", \"`unknown`\");\n",
        "- `default`: Indicates if the customer has credit in default (_categorical_, _nominal_: \"`no`\", \"`yes`\", \"`unknown`\");\n",
        "- `balance`: The customer's average yearly balance in Euro (_numerical_, _continuous_);\n",
        "- `housing`: Indicates if the customer has a housing loan (_categorical_, _nominal_: \"`no`\", \"`yes`\", \"`unknown`\");\n",
        "- `loan`: Indicates if the customer has a personal loan (_categorical_, _nominal_: \"`no`\", \"`yes`\", \"`unknown`\");\n",
        "- `contact`:  The customer's contact medium type (_categorical_, _nominal_: \"`cellular`\", \"`telephone`\");\n",
        "- `day`: Last contact day of the month (_numerical_, _discrete_: ranging from `1` to `31`);\n",
        "- `month`: Last contact month of year (_categorical_, _nominal_: \"`jan`\", \"`feb`\", \"`mar`\", ..., \"`nov`\", \"`dec`\");\n",
        "- `duration`: Last contact duration, in seconds (_numerical_, _continuous_). [**NOTE:** This attribute highly affects the output target (e.g., if `duration = 0` then `deposit = \"no\"`). Yet, the duration is not known before a call is performed. Also, after the end of the call `deposit` is obviously known. Thus, this feature should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.]\n",
        "- `campaign`: The number of contacts performed during this campaign and for this customer (_numerical_, _discrete_) [**NOTE:** includes last contact];\n",
        "- `pdays`: The number of days that passed by after the client was last contacted from a previous campaign (_numerical_, _discrete_) [**NOTE:** `999` means client was not previously contacted];\n",
        "- `previous`: The number of contacts performed before this campaign and for this client (_numerical_, _discrete_);\n",
        "- `poutcome`: The outcome of the previous marketing campaign (_categorical_, _nominal_: \"`failure`\", \"`nonexistent`\", \"`success`\");\n",
        "- **`deposit`**: Indicates if the customer subscribed a term deposit (_categorical_, _nominal_: \"`yes`\", \"`no`\") **[This is the _binary target_ variable we want to predict]**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsHSUHEzDS1-"
      },
      "source": [
        "# Let's define some constants which we will use throughout this notebook\n",
        "NUMERICAL_FEATURES = [\"age\", \n",
        "                      \"balance\",\n",
        "                      \"day\",\n",
        "                      \"duration\",\n",
        "                      \"campaign\",\n",
        "                      \"pdays\",\n",
        "                      \"previous\"\n",
        "                      ]\n",
        "CATEGORICAL_FEATURES = [\"job\", \n",
        "                        \"marital\", \n",
        "                        \"education\", \n",
        "                        \"default\", \n",
        "                        \"housing\",\n",
        "                        \"loan\",\n",
        "                        \"contact\",\n",
        "                        \"month\",\n",
        "                        \"poutcome\"\n",
        "                        ]\n",
        "TARGET_VARIABLE = \"deposit\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pME8ArdkEt_M"
      },
      "source": [
        "print(\"{:d} Numerical features = [{:s}]\".format(len(NUMERICAL_FEATURES), \", \".join([\"`{:s}`\".format(nf) for nf in NUMERICAL_FEATURES])))\n",
        "print(\"{:d} Categorical features = [{:s}]\".format(len(CATEGORICAL_FEATURES), \", \".join([\"`{:s}`\".format(nf) for nf in CATEGORICAL_FEATURES])))\n",
        "print(\"1 Target variable = `{:s}`\".format(TARGET_VARIABLE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pjib1fiylb6"
      },
      "source": [
        "### **Display the first 5 rows of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4v-Z92rGXoe"
      },
      "source": [
        "bank_df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Df7cSAKmqQi"
      },
      "source": [
        "### **Check for any missing values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubkWy6w6mtvG"
      },
      "source": [
        "for c in bank_df.columns:\n",
        "  print(\"N. of missing values of column `{:s}` = {:d}\".format(c, bank_df.where(col(c).isNull()).count()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHTM4wS2ztOJ"
      },
      "source": [
        "# **2. Data Exploration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TKWRYgl3jPi"
      },
      "source": [
        "### **Summary of Descriptive Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvTv38i73pVh"
      },
      "source": [
        "bank_df.describe().toPandas().transpose() # Transpose will allow a better visualization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK1VjwrvN4BV"
      },
      "source": [
        "# To access plotting libraries, we need to first transform our PySpark DataFrame into a Pandas DataFrame\n",
        "bank_pdf = bank_df.toPandas() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okVR9377jPTf"
      },
      "source": [
        "# Set some default plotting configuration using seaborn properties\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.set_context(\"notebook\", rc={\"lines.linewidth\": 2, \n",
        "                                \"xtick.labelsize\":14, \n",
        "                                \"ytick.labelsize\":14,\n",
        "                                \"axes.labelsize\": 18,\n",
        "                                \"axes.titlesize\": 20,\n",
        "                                })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlRGHd9WOr5i"
      },
      "source": [
        "### **Analysis of Data Distributions: Numerical Features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhurS5pHdoQK"
      },
      "source": [
        "### 1. Distributions of individual numerical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8esOySR-Oh1Q"
      },
      "source": [
        "# Plot the distribution of values of each column of interest\n",
        "n_rows = 4\n",
        "n_cols = 2\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14,20))\n",
        "\n",
        "for i,f in enumerate(NUMERICAL_FEATURES): \n",
        "    _ = sns.histplot(data=bank_pdf, x=f, kde=True, color=\"#ca0020\", line_kws={'lw': 1.5}, facecolor=\"#92c5de\", edgecolor=\"black\", ax=axes[i//n_cols, i%n_cols])\n",
        "\n",
        "fig.delaxes(axes[3][1]) # Remove the last cell of the plot\n",
        "\n",
        "fig.tight_layout(pad=1.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ZGhb9NdzgS"
      },
      "source": [
        "### 2. Pairwise regression plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af5ThlVWbOry"
      },
      "source": [
        "# Let's now plot the pairwise relationship between our numerical features\n",
        "_ = sns.pairplot(data=bank_pdf, \n",
        "                 vars=sorted(NUMERICAL_FEATURES), \n",
        "                 hue=TARGET_VARIABLE, \n",
        "                 kind=\"reg\",\n",
        "                 diag_kind='hist',\n",
        "                 diag_kws = {'alpha':0.55, 'bins':20},\n",
        "                 markers=[\"o\", \"s\"]\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJABTcqqKZa8"
      },
      "source": [
        "### **Observations**\n",
        "\n",
        "It is quite evident that there aren't highly correlated numeric features. Therefore, we will initially keep all of them for the model. Note that the feature `day` does not seem really informative (i.e., it is kind of uniformly distributed across all of its values for customers who both decide to opt for a deposit and for those who don't)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHB3xBzKjGui"
      },
      "source": [
        "### **Analysis of Data Distributions: Categorical Features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TKUbjOPmPkE"
      },
      "source": [
        "### 1. Histograms of individual categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2MARb4wkMOP"
      },
      "source": [
        "# For categorical variables, 'countplot' is the way to go\n",
        "# Create a Figure containing 3x3 subplots\n",
        "n_rows = 3\n",
        "n_cols = 3\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14,14))\n",
        "\n",
        "for i,f in enumerate(sorted(CATEGORICAL_FEATURES)): \n",
        "    ax = sns.histplot(data=bank_pdf, x=f, kde=False, facecolor=\"#92c5de\", edgecolor=\"black\", ax=axes[i//n_cols, i%n_cols])\n",
        "    _ = ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "\n",
        "fig.tight_layout(pad=1.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0n4l939pdN-"
      },
      "source": [
        "### 2. Relationship between _categorical_ features and the _target variable_ (`deposit`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAJ-CjTzmpQc"
      },
      "source": [
        "n_rows = 3\n",
        "n_cols = 3\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14,14))\n",
        "\n",
        "i = 0\n",
        "for c in sorted(CATEGORICAL_FEATURES):\n",
        "    tmp_data = pd.crosstab(bank_pdf.loc[:, c], bank_pdf[TARGET_VARIABLE])\n",
        "    # pandas.crosstab returns an mxn table where m is the number of values for the first argument (x) \n",
        "    # and n for the second argument (y)\n",
        "    # As the second argument is always `TARGET_VARIABLE` (i.e., `deposit`), n = 2 (`deposit` is binary!)\n",
        "    # e.g., x = 'housing'; y = 'deposit'\n",
        "    # the following apply is used to transform the crosstab into a \"normalized\" table as follows:\n",
        "    # each entry in the table displays how the i-th categorical value of x (i.e., i-th row) is distributed across\n",
        "    # all the possible values of y (i.e., Y/N)\n",
        "    tmp_data = tmp_data.apply(lambda x: x/tmp_data.sum(axis=1))\n",
        "    ax = tmp_data.plot.bar(stacked=True, color=['red','green'], grid=False, ax=axes[i//n_cols, i % n_cols], legend=True)\n",
        "    _ = ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
        "    i += 1\n",
        "\n",
        "fig.tight_layout(pad=1.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66pFGdch-BU_"
      },
      "source": [
        "# **3. The Learning Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4-GszAFNmSc"
      },
      "source": [
        "### **Balanced vs. Unbalanced Dataset**\n",
        "\n",
        "So far, we haven't looked at how the binary target variable `deposit` is distributed across the instances of our dataset. In this \"lucky\" example, we know that _positive_ examples (i.e., instances where `deposit = 1`) and _negative_ examples (i.e., instances where `deposit = 0`) are somehow balanced (i.e., around 50% of the instances are positives and the other 50% are negatives). That is due to the way this sample dataset has been extracted from the original one.\n",
        "\n",
        "Most often, though, we have to deal with (very) unbalanced datasets where the minority class (which is usually the one we are interested in!) is accounting only for a small fraction of the total number of training instances. For example, consider the click-through rate (CTR) prediction problem, where we want to foresee whether an advertisement (or, in general, a web page) will be clicked by a user. There, most of the advertisements will not be clicked (negatives), whilst only a tiny fraction (even smaller than 1%) of them will be.\n",
        "\n",
        "The fact that a dataset is balanced (respectively, unbalanced) affects the process which we should use to correctly splitting it into _training_ and _test_ set. In particular:\n",
        "\n",
        "- If the dataset is (almost) balanced, we can safely use a **simple random sampling** strategy, which assigns to every instance the same probability of being selected (i.e., if there are $m$ instances, each one will be picked with the same uniform probability $p = 1/m$);\n",
        "- If the dataset is (very) unbalanced, simple random sampling might lead to a poor splitting strategy, where - for instance - the test set ends up containing only examples that are labeled with the most representative class. To overcome such an issue, **stratified random sampling** is the right choice to take as it guarantees that both the training and the test split follow the same class distribution observed in the original dataset (e.g., if the dataset contains 99% of negative instances and 1% of positive ones, so will the training and the test set). This works by first \"stratifying\" the data according to the two groups (i.e., positives vs. negatives), and within each group apply simple random sampling. For example, if our original dataset contains $m$ instances so that $m = m^+ + m^-$ and $m^+ \\ll m^-$ (e.g., $\\frac{m^+}{m} = 0.01)$ and we want to sample $k < m$ instances out of the dataset, we will first stratify the original dataset and will select $k^+ = \\frac{km^+}{m}$ positive instances and $k^- = \\frac{km^-}{m}$ negative instances, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbBHU28yS36r"
      },
      "source": [
        "### Let's first verify our dataset is actually _balanced_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF1A7XAsS911"
      },
      "source": [
        "bank_df.groupBy(TARGET_VARIABLE).count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlUz0-TNb4Jo"
      },
      "source": [
        "### **Dataset Splitting: Training vs. Test Set**\n",
        "\n",
        "Before moving along with any preprocessing involving data transformations, we will split our dataset into **2** portions:\n",
        "- _training set_ (e.g., accounting for **80%** of the total number of instances);\n",
        "- _test set_ (e.g., accounting for the remaining **20%** of instances)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSzZLA9QcA_P"
      },
      "source": [
        "# Randomly split our original dataset `house_df` into 80รท20 for training and test, respectively\n",
        "train_df, test_df = bank_df.randomSplit([0.8, 0.2], seed=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRIWWJnJLo7g"
      },
      "source": [
        "print(\"Training set size: {:d} instances\".format(train_df.count()))\n",
        "print(\"Test set size: {:d} instances\".format(test_df.count()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh179KdCcS81"
      },
      "source": [
        "### **Working on the Training Set only**\n",
        "\n",
        "From now on, we will be working on the training set portion only. The test set will come back into play when we evaluate our learned model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11HcGwvdg90A"
      },
      "source": [
        "### **Transform Categorical features into Numerical using One-Hot Encoding**\n",
        "\n",
        "Note that this step is not always mandatory (e.g., decision trees are able to work nicely with categorical features without the need of transforming them to numerical). Still, other methods (like logistic regression) are designed to operate with numerical inputs only.\n",
        "\n",
        "To transform _categorical_ features into _numerical_ ones we proceed as follows.\n",
        "We setup a pipeline which is composed of the following steps:\n",
        "- [`StringIndexer`](https://spark.apache.org/docs/latest/ml-features#stringindexer): encodes a string column of labels to a column of label indices. The indices are in `[0, numLabels)`, and 4 ordering options are supported (default `frequencyDesc`, which assigns the most frequent label the index `0`, and so on and so forth).\n",
        "- [`OneHotEncoder`](https://spark.apache.org/docs/latest/ml-features#onehotencoder): maps a categorical feature, represented as a label index, to a binary vector with at most a single one-value indicating the presence of a specific feature value from among the set of all feature values. An important parameter is `handleInvalid`, which indicates how to deal with previously unseen labels. By default this raises an error but it can be set to as `keep` to assign previously unseen labels a fallback value.\n",
        "- [`VectorAssembler`](https://spark.apache.org/docs/latest/ml-features#vectorassembler): is a transformer that combines a given list of columns into a single vector column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEHqXC-yvTft"
      },
      "source": [
        "# This function is responsible to implement the pipeline above for transforming categorical features into numerical ones\n",
        "def to_numerical(df, numerical_features, categorical_features, target_variable):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        - df: the input dataframe\n",
        "        - numerical_features: the list of column names in `df` corresponding to numerical features\n",
        "        - categorical_features: the list of column names in `df` corresponding to categorical features\n",
        "        - target_variable: the column name in `df` corresponding to the target variable\n",
        "\n",
        "    Return:\n",
        "        - transformer: the pipeline of transformation fit to `df` (for future usage)\n",
        "        - df_transformed: the dataframe transformed according to the pipeline\n",
        "    \"\"\"\n",
        "    \n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "\n",
        "\n",
        "    # 1. Create a list of indexers, i.e., one for each categorical feature\n",
        "    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n",
        "\n",
        "    # 2. Create the one-hot encoder for the list of features just indexed (this encoder will keep any unseen label in the future)\n",
        "    encoder = OneHotEncoder(inputCols=[indexer.getOutputCol() for indexer in indexers], \n",
        "                                    outputCols=[\"{0}_encoded\".format(indexer.getOutputCol()) for indexer in indexers], \n",
        "                                    handleInvalid=\"keep\")\n",
        "\n",
        "    # 3. Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n",
        "    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n",
        "    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n",
        "    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n",
        "    \n",
        "    # 4. Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n",
        "    assembler = VectorAssembler(inputCols=encoder.getOutputCols() + numerical_features, outputCol=\"features\")\n",
        "\n",
        "    # 5. Populate the stages of the pipeline\n",
        "    stages = indexers + [encoder] + [label_indexer] + [assembler]\n",
        "\n",
        "    # 6. Setup the pipeline with the stages above\n",
        "    pipeline = Pipeline(stages=stages)\n",
        "\n",
        "    # 7. Transform the input dataframe accordingly\n",
        "    transformer = pipeline.fit(df)\n",
        "    df_transformed = transformer.transform(df)\n",
        "\n",
        "    # 8. Eventually, return both the transformed dataframe and the transformer object for future transformations\n",
        "    return transformer, df_transformed "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPaamUYtJh-0"
      },
      "source": [
        "# Remove `duration` from the list of NUMERICAL_FEATURES\n",
        "NUMERICAL_FEATURES.remove(\"duration\")\n",
        "print(\"Removing `duration` from the set of numerical features: [{:s}]\".format(\", \".join([nf for nf in NUMERICAL_FEATURES])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueRiKbiTxJsr"
      },
      "source": [
        " # Transform the training set and get back both the transformer and the new dataset\n",
        "oh_transformer, oh_train_df = to_numerical(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTix1SBg71Xr"
      },
      "source": [
        "# Show the result of numerical transformation\n",
        "oh_train_df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYpzQRWqyxUx"
      },
      "source": [
        "# Select `features` and `label` (i.e., formerly `deposit`) target variable only\n",
        "train = oh_train_df.select([\"features\", \"label\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2pZg_Pey-yP"
      },
      "source": [
        "train.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teSVf-WFzvs-"
      },
      "source": [
        "# **Logistic Regression**\n",
        "\n",
        "We first train a logistic regression model, using the training set above. To do so, we use the `LogisticRegression` object provided by the [PySpark API](https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression) within the package `pyspark.ml.classification`.\n",
        "\n",
        "The API is similar to the one we have seen for Linear Regression (i.e., implementing the **Elastic Net** regularization framework), except for the loss function which now is **cross-entropy** rather than **mean squared error**:\n",
        "$$\n",
        "\\boldsymbol{\\theta}^* = \\text{argmin}_{\\boldsymbol{\\theta}\\in \\mathbb{R}^n} \\frac{1}{m} \\sum_{i=1}^m \\log_e(1 + e^{-y_i\\boldsymbol{\\theta}^T\\mathbf{x}_i}) + \\lambda\\Big(\\alpha |\\boldsymbol{\\theta}| + (1-\\alpha)||\\boldsymbol{\\theta}||^2\\Big)\n",
        "$$\n",
        "In particular, we can specify the following parameters:\n",
        "\n",
        "- `regParam` is the regularization parameter (or $\\lambda$);\n",
        "- `elasticNetParam` is the tradeoff parameter for regularization penalties (or $\\alpha$);\n",
        "  - `regParam = 0` and `elasticNetParam = 0` means there is no regularization;\n",
        "  - `regParam > 0` and `elasticNetParam = 0` means there is only L2-regularization; \n",
        "  - `regParam > 0` and `elasticNetParam = 1` means there is only L1-regularization;\n",
        "  - `regParam > 0` and `0 < elasticNetParam < 1` means there is both L1- and L2-regularization (Elastic Net);\n",
        "\n",
        "As it is always the case, the optimal values of those **hyperparameters** should be tuned using a dedicated portion of the dataset (i.e., **validation set**) or by performing $k$**-fold cross validation**.\n",
        "\n",
        "**A Note on the Optimizer**\n",
        "\n",
        "Spark implements two algorithms to solve logistic regression: **Mini-Batch Gradient Descent** ([`pyspark.mllib.classification.LogisticRegressionWithSGD`](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=logisticregressionwithsgd)) and **L-BFGS** ([`pyspark.mllib.classification.LogisticRegressionWithLBFGS`](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html?highlight=logisticregressionwithlbfgs)). By default, it uses (and recommends) L-BFGS as it generally converges faster than gradient descent due to the fact that it is a **second-order** optimization method (as opposed to **first-order** like gradient descent)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmgq2uMK0AMF"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression # This corresponds to LogisticRegressionWithLBFGS\n",
        "\n",
        "# This setting corresponds to no regularization at all (i.e., both regParam=0 and elasticNetParam=0)\n",
        "log_reg = LogisticRegression(featuresCol = \"features\", labelCol = \"label\", maxIter=100)\n",
        "log_reg_model = log_reg.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf8I0bal0hsi"
      },
      "source": [
        "### **Intercept ($\\theta_0$) and Coefficients ($\\theta_1, \\ldots, \\theta_n$)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyWx968q0zdk"
      },
      "source": [
        "print(\"Intercept: {:.5f}\".format(log_reg_model.intercept))\n",
        "print(\"{:d} Coefficients: [{:s}]\".format(len(log_reg_model.coefficients), \",\".join([\"{:.3f}\".format(c) for c in log_reg_model.coefficients])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfoJ6ySZIj-T"
      },
      "source": [
        "### **Plot Coefficients**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B0LFPBAIdI_"
      },
      "source": [
        "theta = np.sort(log_reg_model.coefficients)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
        "_ = sns.lineplot(x=range(0,len(log_reg_model.coefficients)), y=theta, marker=\"o\", axes=ax)\n",
        "_ = ax.set_xlabel(\"Theta Index\", labelpad=20)\n",
        "_ = ax.set_ylabel(\"Theta Value (log odds)\", labelpad=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QEPpDoV1JnK"
      },
      "source": [
        "### **Summarize model performance on the Training Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_euzi5eVpEj"
      },
      "source": [
        "# Collect training summary\n",
        "training_summary = log_reg_model.summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwMYv9wBVgU-"
      },
      "source": [
        "#### **Precision vs. Recall**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihYAjdDSVnHq"
      },
      "source": [
        "precision_recall = training_summary.pr.toPandas()\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
        "_ = sns.lineplot(x=precision_recall['recall'], y=precision_recall['precision'], marker=\"s\", axes=ax)\n",
        "_ = ax.set_xlabel(\"Recall\", labelpad=20)\n",
        "_ = ax.set_ylabel(\"Precision\", labelpad=20)\n",
        "_ = ax.set_title(\"Precision vs. Recall\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7HfPpUAVdva"
      },
      "source": [
        "#### **Receiver-Operating Characteristic (ROC) and Area Under the ROC (AUC)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsID3E0r07i5"
      },
      "source": [
        "roc = training_summary.roc.toPandas()\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8,6))\n",
        "_ = sns.lineplot(x=roc['FPR'], y=roc['TPR'], marker=\"s\", axes=ax)\n",
        "_ = ax.set_xlabel(\"False Positive Rate\", labelpad=20)\n",
        "_ = ax.set_ylabel(\"True Positive Rate\", labelpad=20)\n",
        "_ = ax.set_title(\"ROC Curve\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T41l1yFIQ78g"
      },
      "source": [
        "# Print out the Area Under the ROC Curve (AUC)\n",
        "print('Training Set AUC: {:.3f}'.format(training_summary.areaUnderROC))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ena6EJ0Y5qhx"
      },
      "source": [
        "### **Use the One-Hot encoding pipeline to transform the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPgeFLQC1S1t"
      },
      "source": [
        "# Here, we use the same transformer as the one returned by the `to_numerical` function above yet applied to the test set\n",
        "oh_test_df = oh_transformer.transform(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoU_fGuA2ivF"
      },
      "source": [
        "oh_test_df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMNJ1NdtwXB8"
      },
      "source": [
        "# Select `features` and `label` only\n",
        "test = oh_test_df.select([\"features\", \"label\"])\n",
        "test.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LokzdSNP6T48"
      },
      "source": [
        "### **Compute predictions on the Test Set according to the model learned on the Training Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-tiLfEA1tml"
      },
      "source": [
        "# `log_reg_model` is a Transformer which can be used to \"transform\" our test set\n",
        "predictions = log_reg_model.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjjN-q_dw8CA"
      },
      "source": [
        "# `predictions` is a dataframe containing (among other things) the predictions made by `log_reg_model` on the test set\n",
        "predictions.select(\"features\", \"prediction\", \"label\").show(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fue7UUz5mom"
      },
      "source": [
        "### **Evaluate model performance on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GySC6TS5c_i"
      },
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "print('Test Set AUC: {:.3f}'.format(evaluator.evaluate(predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKWC5LfR6ibL"
      },
      "source": [
        "## **Tuning Hyperparameters**\n",
        "\n",
        "In the following, we try to summarize the whole pipeline making use also of $k$-fold cross validation to get a better estimate of the generalization performance of our logistic regression model.\n",
        "\n",
        "More specifically, we will tune the two hyperparameters: $\\lambda$ = `regParam` and $\\alpha$ = `elasticNetParam`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux02QmTg7_Ps"
      },
      "source": [
        "# This function defines the general pipeline for logistic regression\n",
        "def logistic_regression_pipeline(train, \n",
        "                                 numerical_features, \n",
        "                                 categorical_features, \n",
        "                                 target_variable, \n",
        "                                 with_std=True,\n",
        "                                 with_mean=True,\n",
        "                                 k_fold=5):\n",
        "\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    from pyspark.ml.classification import LogisticRegression\n",
        "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "    from pyspark.ml import Pipeline\n",
        "\n",
        "    # Configure a logistic regression pipeline, which consists of the following stages: \n",
        "    # 1) convert categorical features to numerical ones\n",
        "    # 2) standardize feature values (optional)\n",
        "    # ... add any other custom transformation here ...\n",
        "    # n) fit a logistic regression model\n",
        "\n",
        "\n",
        "    # 1.a Create a list of indexers, i.e., one for each categorical feature\n",
        "    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n",
        "\n",
        "    # 1.b Create the one-hot encoder for the list of features just indexed (this encoder will keep any unseen label in the future)\n",
        "    encoder = OneHotEncoder(inputCols=[indexer.getOutputCol() for indexer in indexers], \n",
        "                                    outputCols=[\"{0}_encoded\".format(indexer.getOutputCol()) for indexer in indexers], \n",
        "                                    handleInvalid=\"keep\")\n",
        "\n",
        "    # 1.c Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n",
        "    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n",
        "    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n",
        "    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n",
        "    \n",
        "    # 1.d Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n",
        "    assembler = VectorAssembler(inputCols=encoder.getOutputCols() + numerical_features, outputCol=\"features\")\n",
        "\n",
        "    # 2.a Create the StandardScaler\n",
        "    # scaler = StandardScaler(inputCol=assembler.getOutputCol(), outputCol=\"std_\"+assembler.getOutputCol(), withStd=with_std, withMean=with_mean)\n",
        "    # ...\n",
        "\n",
        "    # 3 Populate the stages of the pipeline with all the preprocessing steps\n",
        "    stages = indexers + [encoder] + [label_indexer] + [assembler] # + [scaler] + ...\n",
        "\n",
        "    # 4. Create the logistic regression transformer\n",
        "    log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=100) # change `featuresCol=std_features` if scaler is used\n",
        "\n",
        "    # 5. Add the logistic regression transformer to the pipeline stages (i.e., the last one)\n",
        "    stages += [log_reg]\n",
        "\n",
        "    # 6. Set up the pipeline\n",
        "    pipeline = Pipeline(stages=stages)\n",
        "\n",
        "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "    # A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
        "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "    # With 3 values for log_reg.regParam ($\\lambda$) and 3 values for log_reg.elasticNetParam ($\\alpha$),\n",
        "    # this grid will have 3 x 3 = 9 parameter settings for CrossValidator to choose from.\n",
        "    param_grid = ParamGridBuilder()\\\n",
        "    .addGrid(log_reg.regParam, [0.0, 0.05, 0.1]) \\\n",
        "    .addGrid(log_reg.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .build()\n",
        "    \n",
        "    cross_val = CrossValidator(estimator=pipeline, \n",
        "                               estimatorParamMaps=param_grid,\n",
        "                               evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n",
        "                               numFolds=k_fold,\n",
        "                               collectSubModels=True # this flag allows us to store ALL the models trained during k-fold cross validation\n",
        "                               )\n",
        "\n",
        "    # Run cross-validation, and choose the best set of parameters.\n",
        "    cv_model = cross_val.fit(train)\n",
        "\n",
        "    return cv_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjnj2jXeRSEJ"
      },
      "source": [
        "cv_model = logistic_regression_pipeline(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHvPkEyEBUOf"
      },
      "source": [
        "# This function summarizes all the models trained during k-fold cross validation\n",
        "def summarize_all_models(cv_models):\n",
        "    for k, models in enumerate(cv_models):\n",
        "        print(\"*************** Fold #{:d} ***************\\n\".format(k+1))\n",
        "        for i, m in enumerate(models):\n",
        "            print(\"--- Model #{:d} out of {:d} ---\".format(i+1, len(models)))\n",
        "            print(\"\\tParameters: lambda=[{:.3f}]; alpha=[{:.3f}] \".format(m.stages[-1]._java_obj.getRegParam(), m.stages[-1]._java_obj.getElasticNetParam()))\n",
        "            print(\"\\tModel summary: {}\\n\".format(m.stages[-1]))\n",
        "        print(\"***************************************\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m50kfzDTRhsd"
      },
      "source": [
        "# Call the function above|\n",
        "summarize_all_models(cv_model.subModels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJyI7BSC8cmA"
      },
      "source": [
        "for i, avg_roc_auc in enumerate(cv_model.avgMetrics):\n",
        "    print(\"Avg. ROC AUC computed across k-fold cross validation for model setting #{:d}: {:.3f}\".format(i+1, avg_roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg_ockQBQjNX"
      },
      "source": [
        "print(\"Best model according to k-fold cross validation: lambda=[{:.3f}]; alfa=[{:.3f}]\".\n",
        "      format(cv_model.bestModel.stages[-1]._java_obj.getRegParam(), \n",
        "             cv_model.bestModel.stages[-1]._java_obj.getElasticNetParam(),\n",
        "             )\n",
        "      )\n",
        "print(cv_model.bestModel.stages[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzVrvU9kJOZj"
      },
      "source": [
        "### **Summarize model performance on the Training Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLgNpJP0JVtw"
      },
      "source": [
        "# `bestModel` is the best resulting model according to k-fold cross validation, which is also entirely retrained on the whole `train_df`\n",
        "training_result = cv_model.bestModel.stages[-1].summary\n",
        "print(\"***** Training Set *****\")\n",
        "print(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(training_result.areaUnderROC))\n",
        "print(\"***** Training Set *****\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yadIWG4pIcrr"
      },
      "source": [
        "### **Using the best model from $k$-fold cross validation to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b01W9KqbSz6c"
      },
      "source": [
        "# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n",
        "# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\n",
        "test_predictions = cv_model.transform(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tlh8G3STxGh"
      },
      "source": [
        "test_predictions.select(\"features\", \"prediction\", \"label\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOA-EKGxU16J"
      },
      "source": [
        "def evaluate_model(predictions, metric=\"areaUnderROC\"):\n",
        "    \n",
        "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "    evaluator = BinaryClassificationEvaluator(metricName=metric)\n",
        "\n",
        "    return evaluator.evaluate(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ulP5vi_VpnP"
      },
      "source": [
        "### **Evaluate model performance on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDEu2HuaaueC"
      },
      "source": [
        "print(\"***** Test Set *****\")\n",
        "print(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(evaluate_model(test_predictions)))\n",
        "print(\"Area Under Precision-Recall Curve: {:.3f}\".format(evaluate_model(test_predictions, metric=\"areaUnderPR\")))\n",
        "print(\"***** Test Set *****\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrzGDwgj8d9x"
      },
      "source": [
        "# **Decision Tree**\n",
        "\n",
        "We now train a decision tree (i.e., classification tree), using the training set above. Remember that decision trees natively handle categorical features, extend to the multi-class classification, do not require feature scaling, and are able to capture non-linearities and feature interactions.\n",
        "\n",
        "We will use the `DecisionTreeClassifier` object provided by the [PySpark API](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassifier) within the package `pyspark.ml.classification`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25AZUOQP8dRW"
      },
      "source": [
        "# This function defines the general pipeline for logistic regression\n",
        "def decision_tree_pipeline(train, \n",
        "                           numerical_features, \n",
        "                           categorical_features, \n",
        "                           target_variable, \n",
        "                           with_std=True,\n",
        "                           with_mean=True,\n",
        "                           k_fold=5):\n",
        "\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    from pyspark.ml.classification import DecisionTreeClassifier\n",
        "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "    from pyspark.ml import Pipeline\n",
        "\n",
        "    # Configure a decision tree pipeline, which consists of the following stages: \n",
        "\n",
        "    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n",
        "\n",
        "    # Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n",
        "    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n",
        "    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n",
        "    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n",
        "    \n",
        "    # Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n",
        "    assembler = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + numerical_features, outputCol=\"features\")\n",
        "\n",
        "    # Populate the stages of the pipeline with all the preprocessing steps\n",
        "    stages = indexers + [label_indexer] + [assembler] # + ...\n",
        "\n",
        "    # Create the decision tree transformer\n",
        "    dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\") # change `featuresCol=std_features` if scaler is used\n",
        "\n",
        "    # 5. Add the decision tree transformer to the pipeline stages (i.e., the last one)\n",
        "    stages += [dt]\n",
        "\n",
        "    # 6. Set up the pipeline\n",
        "    pipeline = Pipeline(stages=stages)\n",
        "\n",
        "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "    # A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
        "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "    # With 3 values for dt.maxDepth and 2 values for dt.impurity\n",
        "    # this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.\n",
        "    param_grid = ParamGridBuilder()\\\n",
        "    .addGrid(dt.maxDepth, [3, 5, 8]) \\\n",
        "    .addGrid(dt.impurity, [\"gini\", \"entropy\"]) \\\n",
        "    .build()\n",
        "    \n",
        "    cross_val = CrossValidator(estimator=pipeline, \n",
        "                               estimatorParamMaps=param_grid,\n",
        "                               evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n",
        "                               numFolds=k_fold,\n",
        "                               collectSubModels=True # this flag allows us to store ALL the models trained during k-fold cross validation\n",
        "                               )\n",
        "\n",
        "    # Run cross-validation, and choose the best set of parameters.\n",
        "    cv_model = cross_val.fit(train)\n",
        "\n",
        "    return cv_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yt2Cdm6F5E6"
      },
      "source": [
        "cv_model = decision_tree_pipeline(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghCWiKI5JS68"
      },
      "source": [
        "# This function summarizes all the models trained during k-fold cross validation\n",
        "\n",
        "def summarize_all_models(cv_models):\n",
        "    for k, models in enumerate(cv_models):\n",
        "        print(\"*************** Fold #{:d} ***************\\n\".format(k+1))\n",
        "        for i, m in enumerate(models):\n",
        "            print(\"--- Model #{:d} out of {:d} ---\".format(i+1, len(models)))\n",
        "            print(\"\\tParameters: maxDept=[{:d}]; impurity=[{:s}] \".format(m.stages[-1]._java_obj.getMaxDepth(), m.stages[-1]._java_obj.getImpurity()))\n",
        "            print(\"\\tModel summary: {}\\n\".format(m.stages[-1]))\n",
        "        print(\"***************************************\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ApTiF_JZOf"
      },
      "source": [
        "summarize_all_models(cv_model.subModels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unM_AG88XauX"
      },
      "source": [
        "for i, avg_roc_auc in enumerate(cv_model.avgMetrics):\n",
        "    print(\"Avg. ROC AUC computed across k-fold cross validation for model setting #{:d}: {:.3f}\".format(i+1, avg_roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDmOgLrXPRJ0"
      },
      "source": [
        "print(\"Best model according to k-fold cross validation: maxDept=[{:d}]; impurity=[{:s}]\".\n",
        "      format(cv_model.bestModel.stages[-1]._java_obj.getMaxDepth(), \n",
        "             cv_model.bestModel.stages[-1]._java_obj.getImpurity(),\n",
        "             )\n",
        "      )\n",
        "print(cv_model.bestModel.stages[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NQVcLGDNplX"
      },
      "source": [
        "### **Using the best model from $k$-fold cross validation to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK-n0LceNplY"
      },
      "source": [
        "# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n",
        "# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\n",
        "test_predictions = cv_model.transform(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haSPSR2bNpla"
      },
      "source": [
        "test_predictions.select(\"features\", \"prediction\", \"label\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjhSbqlPNple"
      },
      "source": [
        "### **Evaluate model performance on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am6H-UvlNple"
      },
      "source": [
        "print(\"***** Test Set *****\")\n",
        "print(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(evaluate_model(test_predictions)))\n",
        "print(\"Area Under Precision-Recall Curve: {:.3f}\".format(evaluate_model(test_predictions, metric=\"areaUnderPR\")))\n",
        "print(\"***** Test Set *****\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlZQURklPG_9"
      },
      "source": [
        "## **Observations**\n",
        "\n",
        "As it turns out, one simple decision tree performed worst than logistic regression because it is too weak given the range of different features (ROC AUC = 0.532 vs. 0.757, respectively). The prediction accuracy of decision trees can be improved by ensemble methods, such as **Random Forests** (**RF**) and **Gradient Boosted Decision Trees** (**GBDT**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5WxSDJBRDNM"
      },
      "source": [
        "# **Random Forests**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvPi4wwwRFwp"
      },
      "source": [
        "# This function defines the general pipeline for logistic regression\n",
        "def random_forest_pipeline(train, \n",
        "                           numerical_features, \n",
        "                           categorical_features, \n",
        "                           target_variable, \n",
        "                           with_std=True,\n",
        "                           with_mean=True,\n",
        "                           k_fold=5):\n",
        "\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    from pyspark.ml.classification import RandomForestClassifier\n",
        "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "    from pyspark.ml import Pipeline\n",
        "\n",
        "    # Configure a random forest pipeline, which consists of the following stages: \n",
        "\n",
        "    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n",
        "\n",
        "    # Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n",
        "    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n",
        "    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n",
        "    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n",
        "    \n",
        "    # Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n",
        "    assembler = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + numerical_features, outputCol=\"features\")\n",
        "\n",
        "    # Populate the stages of the pipeline with all the preprocessing steps\n",
        "    stages = indexers + [label_indexer] + [assembler] # + ...\n",
        "\n",
        "    # Create the random forest transformer\n",
        "    rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\") # change `featuresCol=std_features` if scaler is used\n",
        "\n",
        "    # 5. Add the random forest transformer to the pipeline stages (i.e., the last one)\n",
        "    stages += [rf]\n",
        "\n",
        "    # 6. Set up the pipeline\n",
        "    pipeline = Pipeline(stages=stages)\n",
        "\n",
        "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "    # A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
        "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "    # With 3 values for rf.maxDepth and 3 values for rf.numTrees\n",
        "    # this grid will have 3 x 3 = 9 parameter settings for CrossValidator to choose from.\n",
        "    param_grid = ParamGridBuilder()\\\n",
        "    .addGrid(rf.maxDepth, [3, 5, 8]) \\\n",
        "    .addGrid(rf.numTrees, [10, 50, 100]) \\\n",
        "    .build()\n",
        "    \n",
        "    cross_val = CrossValidator(estimator=pipeline, \n",
        "                               estimatorParamMaps=param_grid,\n",
        "                               evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n",
        "                               numFolds=k_fold,\n",
        "                               collectSubModels=True # this flag allows us to store ALL the models trained during k-fold cross validation\n",
        "                               )\n",
        "\n",
        "    # Run cross-validation, and choose the best set of parameters.\n",
        "    cv_model = cross_val.fit(train)\n",
        "\n",
        "    return cv_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ch6K6w6SH1n"
      },
      "source": [
        "cv_model = random_forest_pipeline(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY_1PB55Y0rJ"
      },
      "source": [
        "for i, avg_roc_auc in enumerate(cv_model.avgMetrics):\n",
        "    print(\"Avg. ROC AUC computed across k-fold cross validation for model setting #{:d}: {:.3f}\".format(i+1, avg_roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2PjmxpqSM5r"
      },
      "source": [
        "print(\"Best model according to k-fold cross validation: maxDept=[{:d}]\".\n",
        "      format(cv_model.bestModel.stages[-1]._java_obj.getMaxDepth(), \n",
        "             )\n",
        "      )\n",
        "print(cv_model.bestModel.stages[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUhN4Kv_TD0b"
      },
      "source": [
        "### **Using the best model from $k$-fold cross validation to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfqhpoelTD0e"
      },
      "source": [
        "# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n",
        "# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\n",
        "test_predictions = cv_model.transform(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEovQrlHTD0h"
      },
      "source": [
        "test_predictions.select(\"features\", \"prediction\", \"label\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFKKUoUfTD0k"
      },
      "source": [
        "### **Evaluate model performance on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3enTDtzTD0l"
      },
      "source": [
        "print(\"***** Test Set *****\")\n",
        "print(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(evaluate_model(test_predictions)))\n",
        "print(\"Area Under Precision-Recall Curve: {:.3f}\".format(evaluate_model(test_predictions, metric=\"areaUnderPR\")))\n",
        "print(\"***** Test Set *****\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI-3MJe_UDPt"
      },
      "source": [
        "## **Observations**\n",
        "\n",
        "Using Random Forest we are able to improve ROC AUC to **0.790** from 0.532 of a single decision tree! Let's see if we can do even better using GBDT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tols6SZpTTL9"
      },
      "source": [
        "# **Gradient Boosted Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQwO_EeRTzjk"
      },
      "source": [
        "# This function defines the general pipeline for logistic regression\n",
        "def gbdt_pipeline(train, \n",
        "                           numerical_features, \n",
        "                           categorical_features, \n",
        "                           target_variable, \n",
        "                           with_std=True,\n",
        "                           with_mean=True,\n",
        "                           k_fold=5):\n",
        "\n",
        "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "    from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "    from pyspark.ml.classification import GBTClassifier\n",
        "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "    from pyspark.ml import Pipeline\n",
        "\n",
        "    # Configure a gradient boosted decision tree pipeline, which consists of the following stages: \n",
        "\n",
        "    indexers = [StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c), handleInvalid=\"keep\") for c in categorical_features]\n",
        "\n",
        "    # Indexing the target column (i.e., transform it into 0/1) and rename it as \"label\"\n",
        "    # Note that by default StringIndexer will assign the value `0` to the most frequent label, which in the case of `deposit` is `no`\n",
        "    # As such, this nicely resembles the idea of having `deposit = 0` if no deposit is subscribed, or `deposit = 1` otherwise.\n",
        "    label_indexer = StringIndexer(inputCol = target_variable, outputCol = \"label\")\n",
        "    \n",
        "    # Assemble all the features (both one-hot-encoded categorical and numerical) into a single vector\n",
        "    assembler = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + numerical_features, outputCol=\"features\")\n",
        "\n",
        "    # Populate the stages of the pipeline with all the preprocessing steps\n",
        "    stages = indexers + [label_indexer] + [assembler] # + ...\n",
        "\n",
        "    # Create the gradient boosted decision tree transformer\n",
        "    gbdt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\") # change `featuresCol=std_features` if scaler is used\n",
        "\n",
        "    # 5. Add the gradient boosted decision tree transformer to the pipeline stages (i.e., the last one)\n",
        "    stages += [gbdt]\n",
        "\n",
        "    # 6. Set up the pipeline\n",
        "    pipeline = Pipeline(stages=stages)\n",
        "\n",
        "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "    # A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
        "    # We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "    # With 3 values for gbdt.maxDepth and 3 values for gbdt.maxIter (i.e., boosting rounds)\n",
        "    # this grid will have 3 x 3 = 9 parameter settings for CrossValidator to choose from.\n",
        "    param_grid = ParamGridBuilder()\\\n",
        "    .addGrid(gbdt.maxDepth, [3, 5, 8]) \\\n",
        "    .addGrid(gbdt.maxIter, [10, 50, 100]) \\\n",
        "    .build()\n",
        "    \n",
        "    cross_val = CrossValidator(estimator=pipeline, \n",
        "                               estimatorParamMaps=param_grid,\n",
        "                               evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"), # default = \"areaUnderROC\", alternatively \"areaUnderPR\"\n",
        "                               numFolds=k_fold,\n",
        "                               collectSubModels=True # this flag allows us to store ALL the models trained during k-fold cross validation\n",
        "                               )\n",
        "\n",
        "    # Run cross-validation, and choose the best set of parameters.\n",
        "    cv_model = cross_val.fit(train)\n",
        "\n",
        "    return cv_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTAMWchwUx3_"
      },
      "source": [
        "cv_model = gbdt_pipeline(train_df, NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_VARIABLE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKJQZlEeY9U9"
      },
      "source": [
        "for i, avg_roc_auc in enumerate(cv_model.avgMetrics):\n",
        "    print(\"Avg. ROC AUC computed across k-fold cross validation for model setting #{:d}: {:.3f}\".format(i+1, avg_roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mslU-QwkU7hg"
      },
      "source": [
        "print(\"Best model according to k-fold cross validation: maxDept=[{:d}]; maxIter=[{:d}]\".\n",
        "      format(cv_model.bestModel.stages[-1]._java_obj.getMaxDepth(), \n",
        "             cv_model.bestModel.stages[-1]._java_obj.getMaxIter()\n",
        "             )\n",
        "      )\n",
        "print(cv_model.bestModel.stages[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3wedGS1XTKl"
      },
      "source": [
        "### **Using the best model from $k$-fold cross validation to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld5P-_CAXTKm"
      },
      "source": [
        "# Make predictions on the test set (`cv_model` contains the best model according to the result of k-fold cross validation)\n",
        "# `test_df` will follow exactly the same pipeline defined above, and already fit to `train_df`\n",
        "test_predictions = cv_model.transform(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuZz4HF0XTKo"
      },
      "source": [
        "test_predictions.select(\"features\", \"prediction\", \"label\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmX-lvcgXTKs"
      },
      "source": [
        "### **Evaluate model performance on the Test Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gyr1FYUXTKs"
      },
      "source": [
        "print(\"***** Test Set *****\")\n",
        "print(\"Area Under ROC Curve (ROC AUC): {:.3f}\".format(evaluate_model(test_predictions)))\n",
        "print(\"Area Under Precision-Recall Curve: {:.3f}\".format(evaluate_model(test_predictions, metric=\"areaUnderPR\")))\n",
        "print(\"***** Test Set *****\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T4xevfjcodJ"
      },
      "source": [
        "## **Final Remarks**\n",
        "\n",
        "GBDT has improved the value of ROC AUC previously obtained by Random Forest to **0.796**: this is the highest score obtained amongst all the models we have evaluated."
      ]
    }
  ]
}